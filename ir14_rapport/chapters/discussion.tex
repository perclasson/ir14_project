
\chapter{Discussion}

It is clear that we can better the results significantly by taking the structure of Wikipedia into account. We can see this starkly when looking at the effects of only considering the first five or ten sentences as possible summaries, compared to considering sentences from the whole documents. Considering how much higher the score is especially when looking for summaries only among the first five of a documents sentences, there is certainly some reason to doubt the use of LexRank for Wikipedia unless you have very high demands for the brevity of the summary. With a little more relaxed limits for how long a summary can be (a single sentence is quite harsh), it may be better to just lift the five first sentences of the article directly. Indeed, we can see that this is what Google does for some searches.

This was not the only way we took the structure of our source data collection into consideration; we also tried to filter out very short pages since we thought the scores sentences in these would get or give during LexRank would not reflect well on the actual importance of sentences. We used the length of the articles as a rough measure of their exhaustiveness and authority on a subject to mitigate that TF-IDF (which Solr uses for searches) gives higher scores to shorter pages. This may have been too hasty, however, as can be seen by the results of the two different values for the minimum amount of sentences needed in a document for it to be considered: We actually got better results from having no lower limit.